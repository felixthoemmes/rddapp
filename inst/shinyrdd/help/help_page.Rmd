---
title: "`rddapp` `shiny` manual"
author: "Felix Thoemmes"
#date: "January 20, 2018"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

`rddapp` is an [`R` package](https://cran.r-project.org/web/packages/rddapp/index.html) with a `shiny` [web app](https://shiny.rstudio.com/) for the analysis of [regression discontinuity designs](https://en.wikipedia.org/wiki/Regression_discontinuity_design) (RDDs). It offers both parametric and non-parametric estimation of causal effects in RDDs, with one or two assignment variables. It also provides numerous assumption checks, and allows the estimation of statistical power.

# Use

## Online
The `rddapp` `shiny` web app can be accessed [online](https://rddapp.shinyapps.io/shinyrdd/). Untested features will first be introduced to the beta [version](https://rddapp.shinyapps.io/shinyrdd_beta/).
The `shiny` environment is fully point-and-click; no programming in `R` is required. Data can be uploaded directly to the `shiny` server for analysis. For sensitive data that must be kept on secure, the use of an offline client is available.

## Offline
To use the `shiny` app offline, `R` must be [installed](https://cran.cnr.berkeley.edu/). Next, open an `R` session and download [the offical rddapp R package from CRAN](https://cran.r-project.org/web/packages/rddapp/index.html). Load the package using the `library(rddapp)` command in the `R` prompt, and then execute the function `shiny_run()`. This command will load the point-and-click `shiny` enviroment in a local browser. No further interaction with the `R` console is required and no data will be transfered over the Internet.

# Interface
At the very top of the `shiny` app are three menu options, labeled [**Model**](#model_page), [**Power**](#power_page), and **More**. The **Model** page is for statistical estimation, the **Power** page is for power analysis, and the **More** menu contains this manual, as well as a simple **About** page.

# Model page {#model_page}
The **Model** page is subdivided into a data panel and a dynamic results panel which appears after the data are loaded.

## Data upload panel
Data are uploaded using the pull-down menu in the **Data** panel. The choices are to upload either a `.sav` file (native file format of `SPSS`), or a `.csv` file (comma separated values).

The user can further fine-tune the data upload by clicking on the small **gear** button at the top right of the panel to reveal additional options depending on the file format chosen.

The **Browse** button appears automatically when the user chooses a `.sav` or `.csv` file and opens a file explorer from which to select the data for upload.

Once the data are loaded, additional panels will appear for the [**Outcome**](#outcome_panel) variable and [**Treatment design**](#treatment_design_panel).

### `.sav` files {#sav_files}

If the user selects an `.sav` file for upload, the **gear** button in the top right of the **Data** panel can be used to display further options.

If the **Use Value Labels** option is selected, value labels from SPSS will be used for the uploaded data. For instance, a user may have coded a categorical variable `0` and `1`, and included corresponding value labels `male` and `female`. When **Use Value Labels** is activated, the actual labels will be displayed; otherwise, the numeric codes will be used.

If the **Use User's Missing Value** option is selected, any user-specified missing values in `SPSS` will be treated as [`NA`](https://www.statmethods.net/input/missingdata.html) in the `R` program.

Finally, the user can indicate that the uploaded file has been multiply imputed (typically to deal with missing values) by selecting a **Multiple Imputation ID** variable from the data. This variable indicates which imputation event each observation corresponds to. All analyses will be performed on each imputation, estimates from each imputation will be averaged, and standard errors will be derived using Rubin's rules (1987), which accounts for the variation both within and between imputations.

### `.csv` files

If the user selects a `.csv` file, the options under the **gear** button allow the user to specify exactly how the `.csv` file is structured.

The user can specify:

* whether any values are enclosed in **quotes** (double `"`, single `'`, or none),
* what kind of **separator** is used between values (comma `,`, semi-colon `;`, tab, or whitespace),
* whether **missing values** are blank by default or if a special character is used (e.g., `NA`),
* whether the file includes a **header** in the first line with variable names. 

Just as for `.sav` files, the user can specify that the file is multiply imputed, and if so which variable is the **Multiple Imputation ID** (see [above](#sav_files) for details).

### CARE example data

The application includes an example data set, named **CARE**. The data are sampled from the Carolina Abecedarian Project and the Carolina Approach to Responsive Education (CARE) study, with the full data set hosted by [ICPSR](http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies/4091). The example data are described briefly in the `rddapp` package [manual](https://cran.r-project.org/web/packages/rddapp/rddapp.pdf), and in detail in the [vignette](https://cran.r-project.org/web/packages/rddapp/vignettes/rddapp.html).

## Outcome panel {#outcome_panel}
The **Outcome** menu allows the user to define the outcome variable: the variable that the researcher believes is affected by the treatment. Additional options for analyzing the outcome variable appear by clicking the **gear** button and include the **Kernel for local linear fitting**, **Type of SE**, and **Auxiliary Variables**.

The **kernel** option specifies which type of kernel should be used for the non-parametric (local linear fitting) analysis, described further in the [**Estimates**](#estimates_tab) section. By default, a triangular kernel is chosen, in line with recommendations of Imbens and Kalyanaraman (XXXX). However, the user can change this to a variety of other kernels, defined by the following functions:

  1. Triangular:   $K(u) = (1 - |u|)$,
  2. Rectangular (uniform):  $K(u) = \frac{1}{2}$,
  3. Epanechnikov: $K(u) = \frac{3}{4} (1 - u^2)$,
  4. Quartic (biweight):      $K(u) = \frac{15}{16} (1 - u^2)^2$,
  5. Triweight:    $K(u) = \frac{35}{32}(1 - u^2)^3$,
  6. Tricube:      $K(u) = \frac{70}{81}(1 - |u|^3)^3$,
  7. Gaussian:     $K(u) = \frac{1}{\sqrt{2\pi}} e^{-u^2/2}$,
  8. Cosine:       $K(u) = \frac{\pi}{4}\cos(\frac{\pi}{2}u)$,

where $|u|\leq 1$, except for with the Gaussian kernel, where $u$ can be any real number. , we recommend the use of the triangular kernel.

The second option under the outcome tab is the type of standard error that should be used. ShinyRDD supports a "usual" standard error, that assumes constant variance ($/sigma ^2 (X'X)^{-1}$). In addition, all types of standard errors that are included in the R package "sandwich" (Zeileis, 2017) are included. By default a heteroskedasticty-robust standard error (HC1) is chosen. For details on the specific choices of heteroskedasticty-robust standard errors, consult Zeileis, 2006.

In addition, a cluster ID may be provided by the user, and a standard error for clustered data may be chosen. The pull-down menu to input this clustering ID opens automatically upon choosing this type of standard error.

The last option under the outcome tab is called "auxiliary variables". In this pull-down menu, users can specify the use of auxiliary variables in the RDD. These variables are integrated in the regressions of the parameteric RDD. Purely linear terms are used for all auxiliary variables, and there is currently no implementation of adding non-linear terms. If users wanted to add non-linear terms, these would have to be created by hand first (e.g., polynomials) and entered as regular auxiliary variables. Further, by default the auxiliary variables will not be entered as interactive terms (interacting with treatment assignment). In a properly executed RDD, it should not be necessary to include auxiliary variables, but inclusion of them can in some instances increase precision of parameter estimates, and thus statistical power.

## Treatment design panel {#treatment_design_panel}
ShinyRDD allows the user fine-grained control over the actual treatment assignment mechanism. Under the box "Treatment receipt" the user should input the treatment variable. With this, we mean the variable that encodes which treatment was _actually_ received by the participants. In a so-called sharp RDD the actual received treatment and the assigned treatment based on the cut-off are identical. In so-called fuzzy designs, the treatment under the assignment rule and the actually received treatment may not be identical.

The treatment mechanism of the RDD is described by (a series) of "if" statements, under the heading "Treatment Design". The first box labeled "primary assignment" should be used for the assignment variable, and the box underneath should be used to input the threshold for being assigned to the treatment. By default the threshold is interpreted that every score _equal_ or larger than the threshold leads to an assignment in the treatment condition. However, the user can change this default, and define that the treatment is applied to individuals who are below the threshold. The gear button, also the user to change the assignment operator from a smaller or equal, and larger or equal, to a strictly smaller, or strictly larger assignment. This defines whether individuals who are right at the cut-off are assigned to the treatment or not. All of this information should be available to the reseachers based on the actual design and assignment rule that was implemented.

As an example, choosing an assignment variable and then selecting, "larger equals" with cut-off value 40, would mean that treatment was assigned to those individuals that were equal or larger to 40. On the other hand choosing, "strictly smaller" and a value of 10, would mean that all individuals are assigned to treatment if they are smaller than 10 on the assignment variable.

Clicking the small "plus" button opens another dynamic menu in which a second assignment variable can be defined. This option accommodates multiple-assignment RDDs, currently up to two assignment variables. All other options that were available for the first assignment variable are also available for the second assignment. One restriction that is in place for these designs is that both assignment rules must be either strictly larger / smaller or equal larger / smaller. Combinations of these two lead to designs in which it is at least theoretically possible to have undefined cases for some analytic approaches.

## Data analysis tab
As soon as data are loaded, the "Data" tab is populated with a spreadsheet-like display of the data. Variable names are displayed at the top, and users can navigate through the data, and sort by each of the variables. This display is mainly for purposes of validating that the data were read in correctly. The user has the option to display all variables in the dataset, or restrict to the view to the variables that are in the actual model, using the "Model Data" tab. As soon as the outcome, and the treatment assignment variables are defined, the data tab is further populated with two additional tables.

Table 1.1 shows descriptive statistics of the treatment variable (T), the assignment variable (A1 - and A2, if a second assignment was chosen), and the outcome variable (O). For each variable, three columns are reported: N (the sample size), M (the mean), and SD (the standard deviation). In addition, a small correlation matrix is shown on the side. The columns of this correlation matrix are labeled with T and O, indicating both treatment, and outcome variable. Within each corresponding row and column, the Pearson correlation coefficient among all three variables is shown in the lower triangle of the matrix. The information in the table can be downloaded as a `.csv` file, by clicking on the small button in the upper right that looks like a notepad.

Table 1.2 summarizes the design of the RDD, and can serve as a check for the researcher that the design was correctly specified. The design summary consists of a tabulation of the sample sizes by treatment assignment, and actual received treatment. In the case of an RDD with a single assignment variable, the actual treatment is displayed in the columns (with labels control and treatment), and the assignment variable (along with the cut-offs) is displayed in the rows. In a sharp RDD (a design in which assigned and received treatment always coincide), the off-diagonal cell counts are always zero. In fuzzy designs, the off-diagonal elements will contain sample sizes of incorrectly classified individuals (treatment assignment and received treatment do not coincide). A parameter $/pi$ is displayed, which is simply the probability of receiving treatment, conditional on being on either side of the threshold. This is computed as a simple conditional probability, P(T=1|A1), and no parametric model is being used to estimate this quantity.

If a second assignment variable is specified, the table is expanded, and an additional column is added. All combinations of cut-offs are displayed as single rows, with their respective sample sizes, and the estimated $/pi$ parameter.
ShinyRDD determines for each dataset, and each given input, whether the design is sharp, or fuzzy, and whether one or two assignment variables were used. In cases, in which one assignment variable does not alter any of the assigned treatment that were based on the first assignment variable, it notes that the second assignment variable is redundant, and call this an "ineffective assignment".

## Assumptions tab
RDDs rely on several assumptions, which are summarized in the assumptions tab. Depending on whether the design is sharp or fuzzy, and relies on one or two assignment variables, the content of the assumption tab will vary. Variations of output are noted whenever they occur.

Figure 2.1 shows the result of McCrary's (2008) sorting test. Briefly described, the sorting test relies on the following idea: in a proper RDD, there should be no discontinuity at the cut-off, because the presence of a discontinuity would imply that participants potentially sorted themselves through other means than just the assignment cut-off. As an example, consider that students are put on the dean's list if their GPA is 3.75 or higher. Teachers who (implicitly or explicitly) want to help their students may round up a grade that is very close to the cut-off. E.g., a teacher may grade the final exam of a student with a GPA of 3.74 more leniently, so that the student can obtain a final GPA of 3.75 and make it on the dean's list. If such behavior is wide-spread, we would assume that we would find less scores of 3.74 or very slightly below, and more scores of 3.75 or slightly above. This would show up as a small bump in the distribution of GPA, right at the cut-off.

The sorting test is implemented as described by McCray (2008). A default binning of the data is conducted (which can be modified by the user). After binning, a non-parametric kernel smoother is applied to both sides of the cut-off using the midpoints of bins and the observed count in each bin as data. The actual test measures the vertical distance of the two edges on both sides of the cut-off, on a log metric. A test statistic $/theta$ (which quantifies the vertical distance), along with a standard error is derived, and tested using a z-test. The z-value and the p-value are reported alongside this test. Ideally, this test should not be significant. A significant test statistic would indicate that the assumption of a faithfully implemented RDD (assignment only due to cut-off) has been violated.

Because the sorting test relies on a non-parametric estimation of the kernel density estimate, it is possible to change parameters of this plot, and the resulting test. The first one is the smoothing parameter, also called band-width. The smooting parameter simply determines how mcuh data is considered at once, when computing the smooth approximation. A large value results in lots of data being considered, and the smoother being very flat. A small number results in narrow bands of data being considered when computing local means, and results in a very jagged line. The choice of bandwidht will naturally result in different test statistics, and possibly different inferential decisions. Generally speaking, a bandwidth parameter should be chosen, so that no over- or under-smoothing occurs. To aid in the selection of the parameter, a graphical display is provided, and updated every time the smoothing parameter changes.

The second graphical parameter is the bin size. The bin size determines the amount of binning of the raw data. The kernel density estimate in the sorting test is not derived from individual datapoints, but from binned means. If the bin size gets smaller, then many bins will have frequencies identical to, or close to 1, and the density estimate will look very flat. If the bin size increases, then there will only be few bins, and the kernel density estimate will tend to be under-smoothed, and only rely on too few bins. Just like the choice of bandwidth, the choice of bin size can be determined either through the default value, or by examining the plot. Every time the bin size is changed, the plot will automatically update.

When changing the parameters, keep in mind that it it is considered bad statistical practice to change the bin size or bandwidth to maximize the p-value in order to make the test look good. Instead either the default should be used, or adjusted in accordance with a properly smoothed plot. The automatic defaults are often good choices, but sometimes some minor adjustment is needed. It is very rare that large adjustments need to be made to the default values.

The assumptions tab will always show the sorting test for the assignment variable itself, and will conduct the test based on the actual observed cut-off that was defined by the user in the data tab. However, it is also possible to perform the sorting test on other variables, by simply clicking the pull-down menu next to the plot of the sorting test. Any covariate in the dataset can be tested for discontinuities using the sorting test.

The plot in Figure 2.1 can be downloaded as a PDF, PNG, or SVG. The test statistic itself can be downloaded in a CSV file.

The second table in the assumptions tab, Table 2.1 offers a small attrition analysis. It provides a simple count and percentages of missing data. The rows display the total sample size, and then report how many cases are missing on the treamtne variable, the outcome, and the assignment variable. This missingness information is further subdivided into the overall sample, only individuals in the control condition, or only individuals in the treatment condition. This information can sometimes be helpful to determine whether any differential attrition occured.

## Estimates tab {#estimates_tab}

The estimates tab is where the user will find point estimates and inferential statistics for the treatment effect. As such, this tab will often be the main interest of the researcher. Because the program allows for a variety of model specifications, the output can get quite lengthy. Table 3.1. contains all results and treatment effect estimates, along with inferential statistics. The table updates automatically depending on the particular design that is being chosen. In addition, the user can expand or reduce the amount of information that is being displayed using several toggle switches at the top right of the table. The total content of the table can be downloaded as a `.csv` file, using the download button at the top of the table.
Because the table automatically adjusts based on the particular design, we divide the following description of the table and the accompaning figure into separate sections for each of the different designs.

### Sharp RDD with a single assignment (with or without covariates)
In the case of sharp RDD with a single assignment, Table 3.1. displays the treatment effect estimates for the parametric model (global model), and the non-parametric model (local model). Each one of them can be toggled off by the user.

By default, the parametric model is shown as the first entry of the table. The parametric model is subdivided into three additional rows. Each row diplays the results of a parametric model with different functional form. The first row shows the treatment effect, estimated using a linear model. In this model the outcome is modeled as a function of the cut-off, and two linear slopes to the right and the left of it. The two linear slopes are allowed to differ from each other, that means the model always includes an interaction effect between the assignment variable, and the treatment status. The row underneath displays results of the parametric model, but instead of a linear slope, a quadratic slope is modeled on each side of the cut-off. Both linear and quadratic component of the slopes are allowed to differ on each side of the cut-off. Finally, there is also a parametric model that includes a cubic component. Again the slopes and their components are allowed to differ on each side of the cut-off. The three different parametric models are run by default to allow the researcher to see whether results hold under a variety of parametric models. By default all parametric models used in the estimation of the treatment effect are estimated using two-stage least-squares estimation, with robust standard errors. The first stage is a model that uses the assignment variable to predict treatment membership. Note that in sharp RDDs, this prediction of treatment assignment will always be perfect (in fact, in sharp RDDs this step is unnecessary, and completely identical to using a single least-squares regression model). In a second stage the predicted values from the first stage are used as predictors of the outcome of interest. The treatment effect is captured in the regression coefficient that is associated with the treatment indicator variable in the second stage least-squares model. The table footnote repeats some of this model information, and can be used as a quick reference. 

For each parametric model, a variety of inferential statistics are reported. The inferential statistics are reporeted in labeled columns. The first column (bandwidth) is empty for all parametric models, because it only applies to non-parametric models. The total sample size is displayed in the column labelled "N". The treatment effect estimate is found under the column heading "Est.", and its associated standard error in the "SE" column. The corresponding z-statistic, and the p-value, are displayed in the columns next to it. Besides the p-value, the table also contains a 95% confidence interval. Lastly, the Cohen's d effect size is shown for each model. This is computed as a mean difference at the cut-off divided by a pooled standard deviation of both groups. 

The lower part of the table contains results for the non-parametric models. These are models in which a bandwidth is chosen that determines how many units away from the cut-off are being used in the estimation of the regression, and how smooth the slopes on either side of the cut-off are modeled. Technically, the program uses the linear model command in R, but uses weighted least-squares. The weights are derived from the bandwidth function. Units that receive zero weight are excluded from the analysis. 

The vast majority of information from the non-parametric models is identical to the information shown above for the parametric models. The non-parametric models have one additional piece of information, which is the bandwidth parameter, and unlike the parametric models, they also differ on the sample size that is being considered for each model. The three parametric models that are shown by default are one with an "optimal" bandwidth, defined by Imbens and Kalyanaraman, one with double of the optimal bandwidth, and one half of the optimal bandwidth. The three different non-parametric models are run by default to allow the researcher to see whether results hold under a variety of different bandwidth (additional robustness checks can be performed in a later tab).

In case a covariate is added, an additional toggle button is shown at the top of the table. It is deactived by default, but once the user activates it, additional rows are added for the covariate. Each row is labeled with a "+" symbol and the name of the covariate. For each covariate, the regression coefficient that describes the (linear) relationship between the covariate and the outcome is displayed, along with all inferential statistics. Note that even though in the table the regression coefficient is displayed under the same column heading "Est.", it does not mean that this is a treatment effect estiamte. It is simply the linear relationship between covariate and outcome variable. The regression coefficient for the covariate is obtained from the same model that is used to estimate the RDD treatment effect. That means, the treatment indicator, and assignment variable are also predictors in this model. It is currently not possible to model the relationship between the covariate and the outcome in a non-linear fashion (e.g., polynomial regression, interacted with the treatment, etc.).  

Figure 3.1. right underneath the table with treatment effect estimates provides a visual display of the treatment effect. Every of the six models shown above can also be individually displayed, or overlaid on top of each other. By default the plot will show raw data values of the assignment variable, and the outcome variable in a scatterplot. With large datasets it may be infeasiable to display all raw data points. To correct for potential over-plotting, the user has the choice to bin the datapoints, using two options: evenly binning, and binning by quartiles. An even binning means that the assignment variable is sub-divided into a user-specified number of bins. In each of those bins, an average on the outcome variable is computed. This average is then plotted as a single point. The user has the choice to change the size of this point in proportion to the sample size in this bin, using the "scale point size" toggle button. In addition, the user may request a 95 % confidence interval around the estimate of the mean. These confidence intervals are simple normal-theory intervals around an observed mean, using the sample size of the number of units in the bin. The alternative binning option is to use quantiles of the assignment variable. Based on the user-specified number of bins, the assignment variable is cut along quantiles. This results in bins that are typically not the same length, but tend to have a more equal number of individuals in them. In order to avoid binning individuals that are on different sides of the cut-off, the binning algorithm will always avoid spanning a bin over the cut-off value. This can sometimes lead to slight distortions in the bin width and sample size within bins. Most noticeably this can lead to a situation in which quantile binning does not end up with an equal amount of individuals in each bin. 

The scatterplot is overlaid with the regression line that corresponds to one or more of the six possible models. By default, the non-parametric optimal model is overlaid. It is shown as a (smooth) regression line that covers all points around the cut-off that were included in the bandwidth (units with zero weights are not used in the construction of the regression line). By default, a 95% confidence band is displayed around the regression line. This band can be toggled on or off, to either show a dashed outline, or a filled area. The width of the confidence interval can be selected by the user, by overriding the value 95 with any other desired value. Clicking inside the box labeled "Predicted Lines" opens up a pull-down menu from which the user can select any model regression line (out of the six possible models) to be overlaid. A regression line can be deleted by clicking in the box and using the backspace button. 

Additional information of the graph (e.g., legends for points and regression lines, axis labels) are done automatically, and cannot be overriden by the user. The plot can be downloaded by clicking the buttons on the top right of the Figure. Supported formats are .PDF, .SVG, and .PNG. 

### Fuzzy RDD with a single assignment (with or without covariates)

## Sensitivities tab

## R Code tab

# Power page {#power_page}

# About

This software was developed by [Felix Thoemmes](https://psychology.cornell.edu/felix-j-thoemmes), [Wang Liao](https://wliao229.github.io/), [Ze Jin](https://www.linkedin.com/in/ze-jin-08045b31), [Wenyu Zhang](http://zwenyu.github.io/), and [Irena Papst](https://github.com/papsti) all at Cornell University. We are happy to receive feedback! Please send it to
![](../www/fjt_email.png)


The project was supported by the [Institute of Education Sciences](https://ies.ed.gov/), [U.S. Department of Education](https://www.ed.gov/), through Grant R305D150029. The opinions expressed are those of the authors and do not represent views of the Institute or the U.S. Department of Education.
